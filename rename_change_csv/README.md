# How to do ETL using Google Cloud Function?

![repo size](https://img.shields.io/github/repo-size/byambaa1982/data_pipeline_in_gcp)
![size](https://img.shields.io/github/languages/code-size/byambaa1982/data_pipeline_in_gcp)
![language count](https://img.shields.io/github/languages/count/byambaa1982/data_pipeline_in_gcp)
![social](https://img.shields.io/github/followers/byambaa1982?style=social)
![stats](https://img.shields.io/github/stars/byambaa1982/data_pipeline_in_gcp?style=social)


All code is in [my github](https://github.com/byambaa1982/data_pipeline_in_gcp/blob/main/main.py)

## Goal: ETL or Extract, Transfer, and Load
Build reliable serverless and cost effective data pipelines in GCP using python.
Thankfully, Google Cloud (GCP) offers some awesome serverless tools where you can run a workflow like this for next to no cost.

In this repo, we will look to do the following:

- Set up Cloud Function and Cloud Storage
- Extract data
- Transform data
- Load data
- Automate our pipeline

## The Workflow

![Alt text](https://storage.googleapis.com/my-image-data-bucket-2021/images/Image.png "Data Pipeline")